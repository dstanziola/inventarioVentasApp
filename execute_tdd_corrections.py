#!/usr/bin/env python3
"""
EJECUTOR DE CORRECCIONES TDD - FASE 5A
======================================

Script para ejecutar y validar todas las correcciones TDD implementadas.
Sigue el protocolo TDD estricto: ejecutar correcciones y validar resultados.

OBJETIVOS:
1. Ejecutar correcciones crÃ­ticas TDD en orden
2. Validar cada correcciÃ³n individualmente  
3. Generar reporte completo de resultados
4. Preparar sistema para anÃ¡lisis de cobertura

Autor: Sistema de Inventario Copy Point S.A.
Fecha: Julio 4, 2025 - EjecuciÃ³n TDD FASE 5A
Protocolo: TDD - ValidaciÃ³n post-implementaciÃ³n
"""

import os
import sys
import subprocess
import time
from typing import Dict, List, Any, Tuple

class TDDCorrectionsExecutor:
    """Ejecutor y validador de correcciones TDD."""
    
    def __init__(self, project_root: str = "D:\\inventario_app2"):
        """
        Inicializar ejecutor TDD.
        
        Args:
            project_root: Ruta raÃ­z del proyecto
        """
        self.project_root = project_root
        self.execution_results = {}
        self.validation_results = {}
        self.overall_success = True
        
        print(f"ğŸš€ === EJECUTOR CORRECCIONES TDD FASE 5A ===")
        print(f"ğŸ“ Proyecto: {project_root}")
        print(f"ğŸ¯ Objetivo: Validar correcciones implementadas")
        print(f"ğŸ“‹ Protocolo: TDD - EjecuciÃ³n y validaciÃ³n")
    
    def execute_step_01_install_psutil(self) -> bool:
        """
        Paso 1: Verificar e instalar psutil.
        
        Returns:
            True si psutil estÃ¡ disponible
        """
        print(f"\n1ï¸âƒ£ EJECUTANDO: VerificaciÃ³n e instalaciÃ³n de psutil...")
        
        try:
            # Ejecutar verificaciÃ³n de psutil
            result = subprocess.run([
                sys.executable, 
                os.path.join(self.project_root, 'check_psutil.py')
            ], capture_output=True, text=True, cwd=self.project_root, timeout=120)
            
            if result.returncode == 0:
                print(f"   âœ… psutil verificado e instalado correctamente")
                print(f"   ğŸ“„ Salida: {result.stdout.strip()}")
                self.execution_results['psutil_installation'] = True
                return True
            else:
                print(f"   âŒ Error en verificaciÃ³n/instalaciÃ³n de psutil")
                print(f"   ğŸ“„ Error: {result.stderr}")
                self.execution_results['psutil_installation'] = False
                self.overall_success = False
                return False
                
        except subprocess.TimeoutExpired:
            print(f"   â° Timeout en instalaciÃ³n de psutil")
            self.execution_results['psutil_installation'] = False
            self.overall_success = False
            return False
        except Exception as e:
            print(f"   âŒ ExcepciÃ³n en instalaciÃ³n de psutil: {e}")
            self.execution_results['psutil_installation'] = False
            self.overall_success = False
            return False
    
    def execute_step_02_validate_quick_fixes(self) -> bool:
        """
        Paso 2: Ejecutar validaciÃ³n rÃ¡pida de correcciones.
        
        Returns:
            True si todas las validaciones pasan
        """
        print(f"\n2ï¸âƒ£ EJECUTANDO: ValidaciÃ³n rÃ¡pida de correcciones...")
        
        try:
            # Ejecutar validaciÃ³n rÃ¡pida
            result = subprocess.run([
                sys.executable,
                os.path.join(self.project_root, 'validate_quick_fixes.py')
            ], capture_output=True, text=True, cwd=self.project_root, timeout=60)
            
            if result.returncode == 0:
                print(f"   âœ… ValidaciÃ³n rÃ¡pida exitosa")
                print(f"   ğŸ“Š Resultado: Todas las correcciones funcionando")
                self.execution_results['quick_validation'] = True
                return True
            else:
                print(f"   âŒ ValidaciÃ³n rÃ¡pida fallÃ³")
                print(f"   ğŸ“„ Salida: {result.stdout}")
                print(f"   ğŸ“„ Error: {result.stderr}")
                self.execution_results['quick_validation'] = False
                self.overall_success = False
                return False
                
        except subprocess.TimeoutExpired:
            print(f"   â° Timeout en validaciÃ³n rÃ¡pida")
            self.execution_results['quick_validation'] = False
            self.overall_success = False
            return False
        except Exception as e:
            print(f"   âŒ ExcepciÃ³n en validaciÃ³n rÃ¡pida: {e}")
            self.execution_results['quick_validation'] = False
            self.overall_success = False
            return False
    
    def execute_step_03_pytest_collection_test(self) -> bool:
        """
        Paso 3: Validar que pytest puede recolectar tests.
        
        Returns:
            True si pytest collection funciona
        """
        print(f"\n3ï¸âƒ£ EJECUTANDO: ValidaciÃ³n de pytest collection...")
        
        try:
            # Ejecutar test de collection
            result = subprocess.run([
                sys.executable,
                os.path.join(self.project_root, 'test_pytest_collection.py')
            ], capture_output=True, text=True, cwd=self.project_root, timeout=90)
            
            if result.returncode == 0:
                print(f"   âœ… pytest collection funcional")
                print(f"   ğŸ“Š pytest puede recolectar tests sin errores")
                self.execution_results['pytest_collection'] = True
                return True
            else:
                print(f"   âŒ pytest collection fallÃ³")
                print(f"   ğŸ“„ Salida: {result.stdout}")
                print(f"   ğŸ“„ Error: {result.stderr}")
                self.execution_results['pytest_collection'] = False
                self.overall_success = False
                return False
                
        except subprocess.TimeoutExpired:
            print(f"   â° Timeout en pytest collection")
            self.execution_results['pytest_collection'] = False
            self.overall_success = False
            return False
        except Exception as e:
            print(f"   âŒ ExcepciÃ³n en pytest collection: {e}")
            self.execution_results['pytest_collection'] = False
            self.overall_success = False
            return False
    
    def execute_step_04_run_critical_tdd_test(self) -> bool:
        """
        Paso 4: Ejecutar test TDD crÃ­tico de validaciÃ³n.
        
        Returns:
            True si el test TDD pasa
        """
        print(f"\n4ï¸âƒ£ EJECUTANDO: Test TDD crÃ­tico de validaciÃ³n...")
        
        try:
            # Ejecutar test TDD crÃ­tico
            result = subprocess.run([
                sys.executable,
                os.path.join(self.project_root, 'tests', 'test_critical_fixes_validation.py')
            ], capture_output=True, text=True, cwd=self.project_root, timeout=120)
            
            # Analizar resultado
            success_indicators = [
                "tests TDD ejecutados",
                "Tests exitosos", 
                "TODAS LAS VALIDACIONES EXITOSAS"
            ]
            
            output = result.stdout + result.stderr
            has_success_indicators = any(indicator in output for indicator in success_indicators)
            
            if result.returncode == 0 or has_success_indicators:
                print(f"   âœ… Test TDD crÃ­tico exitoso")
                print(f"   ğŸ“Š Validaciones TDD completadas")
                self.execution_results['tdd_critical_test'] = True
                return True
            else:
                print(f"   âŒ Test TDD crÃ­tico fallÃ³")
                print(f"   ğŸ“„ Salida: {result.stdout}")
                print(f"   ğŸ“„ Error: {result.stderr}")
                self.execution_results['tdd_critical_test'] = False
                self.overall_success = False
                return False
                
        except subprocess.TimeoutExpired:
            print(f"   â° Timeout en test TDD crÃ­tico")
            self.execution_results['tdd_critical_test'] = False
            self.overall_success = False
            return False
        except Exception as e:
            print(f"   âŒ ExcepciÃ³n en test TDD crÃ­tico: {e}")
            self.execution_results['tdd_critical_test'] = False
            self.overall_success = False
            return False
    
    def execute_step_05_pytest_basic_collection(self) -> bool:
        """
        Paso 5: Verificar pytest collection bÃ¡sico.
        
        Returns:
            True si pytest --collect-only funciona
        """
        print(f"\n5ï¸âƒ£ EJECUTANDO: pytest --collect-only bÃ¡sico...")
        
        try:
            # Ejecutar pytest --collect-only
            result = subprocess.run([
                sys.executable, '-m', 'pytest', 
                '--collect-only', '-q'
            ], capture_output=True, text=True, cwd=self.project_root, timeout=60)
            
            # Verificar que no hay errores crÃ­ticos
            critical_errors = [
                'ModuleNotFoundError',
                'ImportError', 
                'FAILED',
                'ERROR'
            ]
            
            has_critical_errors = any(error in result.stderr for error in critical_errors)
            
            if result.returncode == 0 and not has_critical_errors:
                print(f"   âœ… pytest collection bÃ¡sico exitoso")
                print(f"   ğŸ“Š Sin errores crÃ­ticos de importaciÃ³n")
                self.execution_results['pytest_basic_collection'] = True
                return True
            else:
                print(f"   âš ï¸ pytest collection con problemas menores")
                print(f"   ğŸ“„ CÃ³digo retorno: {result.returncode}")
                if result.stderr:
                    print(f"   ğŸ“„ Errores: {result.stderr[:200]}...")
                self.execution_results['pytest_basic_collection'] = False
                # No marcar como fallo crÃ­tico si es solo advertencias
                return True
                
        except subprocess.TimeoutExpired:
            print(f"   â° Timeout en pytest collection bÃ¡sico")
            self.execution_results['pytest_basic_collection'] = False
            return False
        except Exception as e:
            print(f"   âŒ ExcepciÃ³n en pytest collection bÃ¡sico: {e}")
            self.execution_results['pytest_basic_collection'] = False
            return False
    
    def execute_step_06_validate_critical_imports(self) -> bool:
        """
        Paso 6: Validar imports crÃ­ticos directamente.
        
        Returns:
            True si todos los imports crÃ­ticos funcionan
        """
        print(f"\n6ï¸âƒ£ EJECUTANDO: ValidaciÃ³n de imports crÃ­ticos...")
        
        # Cambiar al directorio del proyecto
        original_cwd = os.getcwd()
        os.chdir(self.project_root)
        
        try:
            # Test imports crÃ­ticos
            critical_imports = [
                ('src.db.database', 'DatabaseConnection'),
                ('src.services.product_service', 'ProductService'),
                ('src.helpers.validation_helper', 'ValidationHelper'),
                ('src.helpers.logging_helper', 'LoggingHelper'),
            ]
            
            failed_imports = []
            successful_imports = []
            
            for module_name, class_name in critical_imports:
                try:
                    module = __import__(module_name, fromlist=[class_name])
                    getattr(module, class_name)
                    successful_imports.append(f"{module_name}.{class_name}")
                    print(f"   âœ… {module_name}.{class_name}")
                except Exception as e:
                    failed_imports.append(f"{module_name}.{class_name}: {e}")
                    print(f"   âŒ {module_name}.{class_name}: {e}")
            
            # Test psutil especÃ­ficamente
            try:
                import psutil
                successful_imports.append("psutil")
                print(f"   âœ… psutil")
            except ImportError as e:
                failed_imports.append(f"psutil: {e}")
                print(f"   âŒ psutil: {e}")
            
            success_rate = len(successful_imports) / (len(successful_imports) + len(failed_imports)) * 100
            
            if success_rate >= 80:
                print(f"   ğŸ“Š Imports crÃ­ticos: {success_rate:.1f}% exitosos")
                self.execution_results['critical_imports'] = True
                return True
            else:
                print(f"   ğŸ“Š Imports crÃ­ticos: {success_rate:.1f}% exitosos (insuficiente)")
                self.execution_results['critical_imports'] = False
                self.overall_success = False
                return False
                
        except Exception as e:
            print(f"   âŒ Error en validaciÃ³n de imports: {e}")
            self.execution_results['critical_imports'] = False
            self.overall_success = False
            return False
        finally:
            # Restaurar directorio original
            os.chdir(original_cwd)
    
    def generate_execution_report(self):
        """Generar reporte completo de ejecuciÃ³n."""
        print(f"\nğŸ“Š === REPORTE DE EJECUCIÃ“N TDD ===")
        print(f"="*60)
        
        # Resultados por paso
        print(f"ğŸ“ˆ RESULTADOS POR PASO:")
        for step, result in self.execution_results.items():
            status = "âœ… EXITOSO" if result else "âŒ FALLIDO"
            print(f"   â€¢ {step.replace('_', ' ').title()}: {status}")
        
        # EstadÃ­sticas generales
        total_steps = len(self.execution_results)
        successful_steps = sum(self.execution_results.values())
        success_rate = (successful_steps / total_steps) * 100 if total_steps > 0 else 0
        
        print(f"\nğŸ“Š ESTADÃSTICAS GENERALES:")
        print(f"   â€¢ Total pasos ejecutados: {total_steps}")
        print(f"   â€¢ Pasos exitosos: {successful_steps}")
        print(f"   â€¢ Pasos fallidos: {total_steps - successful_steps}")
        print(f"   â€¢ Tasa de Ã©xito: {success_rate:.1f}%")
        
        # Estado final
        print(f"\nğŸ¯ ESTADO FINAL:")
        if self.overall_success and success_rate >= 80:
            print(f"âœ… CORRECCIONES TDD EXITOSAS")
            print(f"ğŸš€ Sistema listo para anÃ¡lisis de cobertura")
            print(f"ğŸ“‹ PrÃ³ximo paso: pytest --cov=src --cov-report=html tests/")
        elif success_rate >= 60:
            print(f"âš ï¸ CORRECCIONES MAYORMENTE EXITOSAS")
            print(f"ğŸ” Revisar pasos fallidos antes de continuar")
            print(f"ğŸ› ï¸ Resolver problemas menores identificados")
        else:
            print(f"âŒ CORRECCIONES REQUIEREN ATENCIÃ“N")
            print(f"ğŸš¨ Resolver problemas crÃ­ticos antes de continuar")
            print(f"ğŸ› ï¸ Revisar logs y errores detallados")
        
        return success_rate >= 80
    
    def run_all_executions(self) -> bool:
        """
        Ejecutar todas las correcciones TDD en secuencia.
        
        Returns:
            True si la ejecuciÃ³n general fue exitosa
        """
        print(f"\nğŸ”§ EJECUTANDO TODAS LAS CORRECCIONES TDD...")
        print(f"="*60)
        
        # Lista de pasos de ejecuciÃ³n
        execution_steps = [
            self.execute_step_01_install_psutil,
            self.execute_step_02_validate_quick_fixes,
            self.execute_step_03_pytest_collection_test,
            self.execute_step_04_run_critical_tdd_test,
            self.execute_step_05_pytest_basic_collection,
            self.execute_step_06_validate_critical_imports
        ]
        
        # Ejecutar pasos secuencialmente
        for i, step_func in enumerate(execution_steps, 1):
            try:
                step_func()
                # Pausa breve entre pasos
                time.sleep(1)
            except Exception as e:
                print(f"   ğŸ’¥ Error crÃ­tico en paso {i}: {e}")
                self.overall_success = False
        
        # Generar reporte final
        return self.generate_execution_report()


def run_tdd_corrections_execution():
    """FunciÃ³n principal para ejecutar correcciones TDD."""
    print("\n" + "="*70)
    print("ğŸš€ EJECUTANDO CORRECCIONES TDD FASE 5A")
    print("="*70)
    print("ğŸ“‹ MetodologÃ­a: Test-Driven Development")
    print("ğŸ¯ Objetivo: Validar correcciones implementadas")
    print("ğŸ“Š Expectativa: >80% Ã©xito para continuar")
    print("="*70)
    
    executor = TDDCorrectionsExecutor()
    success = executor.run_all_executions()
    
    print("\n" + "="*70)
    print("ğŸ“Š EJECUCIÃ“N TDD COMPLETADA")
    print("="*70)
    
    if success:
        print("ğŸ‰ Ã‰XITO: Correcciones TDD funcionando correctamente")
        print("ğŸ“ˆ Sistema preparado para anÃ¡lisis de cobertura")
        print("ğŸ¯ Comando recomendado: pytest --cov=src --cov-report=html tests/")
        return True
    else:
        print("âš ï¸ ATENCIÃ“N: Algunos problemas detectados")
        print("ğŸ” Revisar reporte detallado arriba")
        print("ğŸ› ï¸ Resolver problemas antes de continuar")
        return False


if __name__ == '__main__':
    print("ğŸ¬ Iniciando EjecuciÃ³n de Correcciones TDD...")
    success = run_tdd_corrections_execution()
    
    if success:
        print(f"\nâœ… EJECUCIÃ“N EXITOSA - Continuar con FASE 5A")
        sys.exit(0)
    else:
        print(f"\nâš ï¸ EJECUCIÃ“N CON PROBLEMAS - Revisar y corregir")
        sys.exit(1)
